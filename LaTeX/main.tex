\documentclass[12pt]{article}

% Estrutura do documento.
\usepackage{geometry}
 \geometry{
 a4paper,
 total={170mm,257mm},
 left=25mm,
 top=25mm,
 right=20mm
 }
 
% Permite que o texto fique justificado
\usepackage[document]{ragged2e}

% Permite colocar palavras com acentos e configura como língua padrão o português
\usepackage[utf8]{inputenc}
\usepackage[brazilian]{babel}

% Permite carregar imagens no documento.
\usepackage{graphicx}
\usepackage{indentfirst}

% Fontes...
%\usepackage{bookman}
%\usepackage{boisik}
\usepackage{kpfonts}

% Para definir o espaçamento entre as linhas
\usepackage{setspace}

% Permite mostrar trechos de códigos/pseudocódigo no documento
\usepackage{listingsutf8}
\usepackage{color}

% Algumas cores
\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{lgray}{rgb}{0.960, 0.960, 0.960}
\definecolor{lblue}{rgb}{0.184, 0.552, 0.654}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}
\definecolor{dkblue}{rgb}{0.109, 0.125, 0.592}

% Define como serão exibidos código no documento.
\lstset{frame=lines,
  inputencoding=utf8/latin1,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  basicstyle={\small\ttfamily},
  numbers=left,
  numbersep=1mm,
  keywordstyle=\color{blue},
  commentstyle=\color{dkgreen},
  stringstyle=\color{mauve},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=3,backgroundcolor=\color{lgray},    
  columns=fullflexible,
  breakautoindent=false,
  framerule=1pt,
  columns=fixed,
  xleftmargin=0.5cm
}

\begin{document}
\justifying
\begin{center}
    % espaçamento 1.5
    \onehalfspacing
    
    \Large{INSTITUTO FEDERAL DO SUL DE MINAS GERAIS}
    
    \normalsize{Campus Poços de Caldas}
    
    \vspace{0.5cm}
    \includegraphics[scale=0.1]{img/pcs-logo.eps}
    
    \LARGE{\textbf{Método de Newton para o Aprendizado do Neurônio Artificial}}
    
    \large{\textbf{Joaquim Augusto Pomarico}$^{1}$, \textbf{Marcos Vinícius Moreira}$^{2}$, \textbf{Otávio Messias Palma}$^{3}$, \textbf{Pablo Borges Martins}$^{4}$, \textbf{Yuri Fernandes de Oliveira}$^{5}$,}
    
    \normalsize{\texttt{joaquim.cioffi@alunos.ifsuldeminas.edu.br$^{1}$}, \texttt{ marcos.moreira@alunos.ifsuldeminas.edu.br$^{2}$}, \texttt{ otavio.palma@alunos.ifsuldeminas.edu.br$^{3}$},\texttt{ pablo.borges@alunos.ifsuldeminas.edu.br$^{4}$},\texttt{ yuri.oliveira@alunos.ifsuldeminas.edu.br$^{5}$}}
    
    Poços de Caldas, 09 de Dezembro de 2019
\end{center}

\noindent\textbf{Resumo:} \textit{Para uma rede neural complexa, com parâmetros muito grandes, a tarefa de encontrar o mínimo dentre vários vales contido em tal superfície é muito difícil e custosa. 
Conforme visto na disciplina, um dos métodos para encontrar tal mínimo é a utilização do Método Gradiente Descendente. Todavia, para redes neurais grandes e com mais de uma camada oculta, o método gradiente se torna menos eficiente.
Um dos problemas para uso do método gradiente em grandes redes é o fato do mesmo utilizar método de otimização para função de primeiro grau, assumindo sempre que a superfície da rede é um plano, sem contar com curvaturas. Uma das soluções para os pontos negativos do método gradiente é aplicação do método de Newton. 
O método de Newton é um método iterativo de aproximação, geralmente utilizado em problemas de otimização de segundo grau e para aproximação de funções.} 

\section{Introdução} 

\begin{itemize}
    \item Utilização do Método de Newton para aprendizado do Neurônio Artificial ao invés do Método do Gradiente visto em sala.
    \item O algorítimo utilizado foi o RNA desenvolvido em sala junto do professor da disciplina, sendo que foram feitas alterações na evolução dos neurônios com a implementação do Método de Newton.
    \item Foi utilizada a linguagem de programação Java e as IDEs VSCode e NetBeans.
    \item Os resultados obtidos não foram compatíveis com os esperados. O método acaba por não convergir diversas vezes, mas quando converge o realiza de forma mais eficiente que o método do Gradiente.
\end{itemize}

\section{Fundamentação teórica}
\begin{itemize}
	 \item Em análise numérica, o método de Newton, desenvolvido por Isaac Newton e Joseph Raphson, tem como objetivo estimar raízes de uma função, para isto escolhe-se uma aproximação inicial para esta e calcula-se a equação da reta tangente (através de uma derivada) da função neste ponto e a interseção dela com o eixo das abcissas, a fim de se encontrar uma melhor aproximação para a raiz. Repetindo-se o processo, cria-se um método iterativo para encontrarmos a raiz da função.
    \item Fórmula do Método de Newton para funções de primeiro grau:
    \begin{equation}
        x_{n+1} = x_n - \frac{f(x_n)}{f'(x_n)}, n \in \mathbb{N}
    \end{equation}
    \begin{center}
        \small{\texttt{Onde o valor inicial de x é estimado no começo da iteração.}}
    \end{center}
    \item Fórmula do Método de Newton para funções de segundo grau:
    \begin{equation}
        x_{n+1} = x_n - \frac{f'(x_n)}{f''(x_n)}, n \in \mathbb{N}
    \end{equation}
    \begin{center}
        \small{\texttt{Onde o valor inicial de x é estimado no começo da iteração.}}
    \end{center}
    
    \item No aprendizado do neurônio, queremos minimizar a fórmula do erro, ou seja, chegar na raiz da função. Utilizando o método de Newton precisamos calcular a derivada primeira e segunda da equação e utilizá-las para atualizar os pesos e o bias.
    
    \item Fórmula do erro:
    \begin{equation}
        erro = (y - f(v(w)))^2
    \end{equation}
    
    \item Derivada do erro:
    \begin{equation}
        erro' = - 2 * x_0 * (y - f(v(w)))
    \end{equation}
    
    \item Derivada segunda do erro:
    \begin{equation}
        erro'' = 2 * x_0^2
    \end{equation}
    
    \item Atualização do pesos do neurônio:
    \begin{equation}
        w_{n+1} = w_n * \eta * \frac{x_0 * erro}{x_0^2}
    \end{equation}
\end{itemize}

\section{Algoritmo}

\begin{itemize}
    \item O algoritmo é fundamentalmente o mesmo implementado em aulas com algumas pequenas alterações. 
    \item A função de ativação definida para uso foi a Limiar segundo conselho do professor. A rede neural artificial escolhida foi o Perceptron, novamente sob conselho do professor, dessa forma, não é possível lidar com mais de 2 camadas.
    \item A Rede Neural Artificial Perceptron é inicializada com o número de entradas adequado ao caso e tem a função de ativação configurada junto do número de épocas e dos vetores de aprendizado (entrada e saída esperada).
    \item Durante o aprendizado, atualiza-se os pesos da entradas a partir do valor inicial estimado, que no caso do algoritmo é gerado de forma aleatória entre 0,0 e 1,0. A cada iteração nova, calcula-se o erro até que este seja zerado, o que significa que o valor desejado foi encontrado.
    \item Utilizando o método de Newton, diferente do Método do Gradiente, temos a possibilidade de estar dividindo por 0, dessa forma trata-se esse caso somente replicando o valor da entrada para a próxima iteração.
    \item No final da iteração mostra-se o erro total da época, caso seja 0 a execução foi bem sucedida, caso contrário não.
    \item No caso de uma execução bem sucedida o valor de saída indicado na linha abaixo será de acordo com os dados de entrada.
    \item A ideia de usar o algoritmo pronto veio da própria sugestão do professor que nos orientou a somente fazer as mudanças no código ao invés de refatorá-lo inteiro. Pode-se aproveitar do código pronto e focar nas alterações necessárias com mais afinco visto que não precisamos nos preocupar com a funcionalidade do código que ja fora definida como confiável previamente.
\end{itemize}

\section{Recursos de implementação}

\begin{itemize}
    \item Foi utilizado apenas a linguagem de programação Java para realização do trabalho.
    \item As IDEs NetBeans e VSCode foram utilizadas para escrever o algoritmo, assim como o GitHub foi utilizado como ferramenta para versionamento de código. Além disso, foi utilizado o GitKraken como interface para versionamento.
    \item Nenhuma biblioteca se mostrou necessária na implementação do Algoritmo.
    \item Nenhuma base de dados se mostrou necessária na implementação do Algoritmo, apenas entradas baseadas em vetores de inteiros com suas respectivas saídas em outro vetor de inteiros.
\end{itemize}

\section{Código fonte}
\begin{itemize}
    \item A execução do código se dá apenas pela execução da Classe Main.
    \item Na Classe Main, a variável dados[][] controla os dados de entrada, e saida[] os dados de saída esperada. A variável entrada[] define os valores que serão testados pelos neurônios e irão gerar sua resposta de acordo com o aprendizado feito anteriormente.
    \item Classe Main
\end{itemize}

\lstinputlisting[language=Java]{codigo/Main.java}

\begin{itemize}
    \item Classe Perceptron - Método aprendizado, responsável por atualizar os valores dos pesos.
\end{itemize}
\lstinputlisting[language=Java]{codigo/Perceptron.java}

\section{Conclusão}

\begin{itemize}
    \item Para aplicação do método de Newton, foram encontradas diversas limitações. O método exige diversos critérios para que os valores venham a convergir e assim obter-se o resultado. No entanto, não foi possível realizar essas verificações sem prejudicar o tempo de execução do código.
    \item Como os valores iniciais são gerados de forma aleatória, em algumas execuções obtivemos os resultados esperados, mas na maioria os pesos divergem e tendem ao infinito, impedindo que o neurônio responda o grupo pertencente a entrada em questão.
    \item O grupo apresentou grande dificuldade em entender e associar o método de newton com o aprendizado do neurônio artificial pois além de haver material escasso para consulta, o código implementado ainda não apresentou o resultado esperado.
\end{itemize}

\end{document}